{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM2t7G3JbgQODIr9fQ+nmh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0ZLOYdfRXif"
      },
      "outputs": [],
      "source": [
        "# curse of dimensionality\n",
        "\n",
        "# 1.feature selection\n",
        "# 2.feature extraction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#curse of dimensionality"
      ],
      "metadata": {
        "id": "jPnbrur2S-eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  we have columns whom we also called as features..\n",
        "#  as much as features \"dimension\" getting start increasing\n",
        "#  accuracy may effected ...may accuracy gets worsen\n",
        "#  4 is the maximum number of features where accuracy\n",
        "#  is best but adding more  features than this may model\n",
        "#  accuracy gets worsen due to  overfitting or noise ...."
      ],
      "metadata": {
        "id": "jESmllVGSgrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# why in higher dimension model does not work properly\n",
        "\n",
        "# reason  is sparsity\n",
        "\n",
        "# as we are incresing the dimension my data points\n",
        "# are getting far away...\n",
        "\n",
        "# example\n",
        "          #  if we take more space to seach my lost\n",
        "          #  voulet then it will be tougher\n",
        "          # to find out the voulet because we know\n",
        "          #  somewhere at roadside my voulet is lost\n",
        "          # so if we add playground campus and so on\n",
        "          # it will be tougher  to finds out\n",
        "          # but we  decrease my area in optimal way then it\n",
        "          # will be easier to find out the data .....\n",
        "\n",
        "  # mathmatics :\n",
        "              # there is 5 points of block in x dimension...\n",
        "    # lets say its height....lets we make another dimension of\n",
        "   # y....of weight .....now  boxes will also be increased...\n",
        "   # before there had 5 boxes no there have 25 boxes but still\n",
        "   # datapoints is still 5.....\n",
        "\n",
        " #   so before we have 5 boxes .... now we have 25 ...if we add\n",
        " #   one more dimensions then boxes will more increases or crosses\n",
        " #   125...\n",
        " #   in knn if we want the class of  any point in graph\n",
        " #   then it find out the .....\n",
        " #   classes of the nearest points ...... because we are going in higher\n",
        " #   dimension then ......the distances gets increasing.......\n",
        " #   due to sparsity...means high dimension ...more volume ...and data\n",
        " #   points is limited ....hence by space increasing the th datapoints gets\n",
        " #    sparse.........\n",
        "\n",
        "\n",
        " # curse of dimensionality\n",
        "\n",
        " # performance decreases\n",
        " # computation\n",
        "\n",
        "\n",
        "# solution\n",
        "# 1.dimensional reduction\n",
        "\n",
        "# a.future selection\n",
        "# > f1,f2,f3 ...f20 columns...\n",
        "# > we take subset f1,f15.f12,f20...\n",
        "# > a.forward selection\n",
        "# > b.backward elimination\n",
        "\n",
        "\n",
        "# b.feature extraction\n",
        "# > PCA\n",
        "# LDA\n",
        "# TSNE\n"
      ],
      "metadata": {
        "id": "ZRR4IT-aUZEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONCLUSION :\n",
        "       #   higher dimensionality is dangerous for model\n",
        "# that why we do dimensional reduction\n",
        "#  either by pca or feature selection"
      ],
      "metadata": {
        "id": "we1GSbgwb2lP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}